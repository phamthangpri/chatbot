{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc82fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e94527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2864f3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e96c97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74073059",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = f\"\"\"\n",
    "Skilled data analyst with 6 years of experience analyzing and mining data, developing algorithms and automating processes to increase business efficiency. Proven expertise in working with large volumes of data and translating complex analytics into actionable insights. Curious and passionate about new technology, eager to implement my skills further to help people work in a different but more efficient and interesting way.\n",
    "RELEVANT PROFESSIONAL EXPERIENCE\n",
    "\n",
    "FREELANCE DATA ANALYST\t07/2022-Present\n",
    "Corum Asset Management - Bank reconciliation\t\n",
    "Corum Asset Management is an independent European asset manager, presented in 7 countries (in the EU and Asia). The Bank Reconciliation project covers the banking transactions for 10 years for all company’s accounts\n",
    "For this job, I provided the cash reconciliation between bank statements and the back office to identify discrepancies and risks:\n",
    "\tDesigned data pipelines (collected, cleaned, and interpreted) for 10 years of bank transactions (more than €10Bn) received from different sources\n",
    "\tDiscovered hundreds of discrepancies by cleaning Back Office data (SQL database) and checking Data Quality\n",
    "\tReconciled automatically 90% of bank transfers and 99% of direct debits by working with the business team, challenging their methodology, and developing the calculation rules and matching techniques. The remaining data needed to be checked manually to verify human errors.\n",
    "\tDiscovered an important gap while analyzing each category of bank statements versus Back Office data (Top-down versus Bottom-up method)\n",
    "\tReported confidential results to the business and technical team, including the output files and user guide for the business team, the progress result for the senior management, and the project's technical documentation.\n",
    "Technical skills: Data Mining, Data Quality, Python, SQL\n",
    "\n",
    "MANAGER AT THE DIGITAL EXPERTISE CENTER - SOPRASTERIA\t9/2021- 2/2022\n",
    "CMA-CGM: Management of data analysis projects for Customer Care Services:\n",
    "CMA-CGM is the biggest container transportation and shipping company in France. It is the world’s 3rd largest container shipping company, using shipping routes in 160 countries. The customer care services in the Head office work with all CMA CGM customer services to improve client satisfaction, especially for the Customer Elites.\n",
    "\tCollaborated with the business team to understand their requirements and then translated them to the technical team\n",
    "\tImplemented new dashboards and KPIs to improve Elite Customer satisfaction and enhance client relationships \n",
    "Tool: Toucan Toco, Qlick, Salesforce\n",
    "\n",
    "SENIOR DATA ANALYST - PWC FRANCE\t 9/2017 – 4/2021\n",
    "Modeling\t\n",
    "Development of scripts to automate economic models to improve business performance, such as:\n",
    "\tAsset Management - Valuation of financial assets: Development of a script to translate complex mathematic formulas developed by actuaries to a user-friendly platform. This helped evaluate financial asset prices (stocks, bonds, real estate assets) in response to economic shocks, inflation, etc. \n",
    "\tBanking sector: Creation of normative dictionaries for banking institutions to facilitate the search for regulatory texts. The script reads a regulatory template in input and then scraps all related regulatory texts of each cell in the template.\n",
    "\tPayroll model: Development of a salary increase simulation model for 5 000 employees with different scenarios and the business rules of each department. This model helps the senior management to make decisions on salary increases and other strategic decisions on Payroll.\n",
    "Languages: Alteryx, Python, DAX, RPA and VBA\n",
    "\n",
    "Data Analysis: \n",
    "\tConducted in-depth analysis of client's data and identified risks and anomalies.\n",
    "\tPerformed end-to-end solutions, including cleaning data, developing scripts, creating data visualizations, and conducting restitution workshops.\n",
    "Examples:\n",
    "o\tSNCF: Analysis of payroll data over 3 years with more than 150 M rows of different fields: remuneration (salary, bonus), paid leaves, etc.\n",
    "SNCF - France's national state-owned railway company, operates the country's national rail traffic. The project was a part of the Annual Audit Job of PwC France in SNCF. Instead of checking a sample of the client’s data, we applied the Data technique to this job to analyze the salary of more than 158 000 SNCF employees.\n",
    "\n",
    "o\tDecathlon: Reconciliation of quarterly turnover between client payment and data reported in the accounting system (more than 800M€/quarter)\n",
    "Decathlon: is a French sporting goods retailer, presented in 60 countries and regions. The project covers the company turnover for more than 300 shops in France\n",
    "Tools: Alteryx, Tableau, Power BI\n",
    "\n",
    "RPA (Robotic Process Automation)\n",
    "Developing and implementing robots for international clients and PwC France:\n",
    "\tPernod Ricard: \n",
    "Pernod Ricard: is the world’s second-largest wine and spirits seller. The RPA project was a part of the Digitalization Project for the Group Finance Department which aimed to improve business efficiency.\n",
    "o\tMarocain office: Generation of customer invoices from purchase orders (daily run)\n",
    "o\tSwedish office: Creation of new supplier records in the accounting system; Automatization of the customs check on foreign clients (weekly run)\n",
    "All these processes are realized today automatically by robots with a validation step at the end of the process\n",
    "\tPwC : \n",
    "o\tData extraction for the Asset Management team (more than 20 000 Excel files downloaded, cleaned and concatenated monthly by robots = 5 full-time juniors + 1 managers  workload)\n",
    "o\tMigration of customer auditing data into the ERP\n",
    "o\tPlanning creation for PwC France employees \n",
    "(65,000 bookings/year = 3 full-time employees workload)\n",
    "Tools: Alteryx, UiPath (RPA)\n",
    "\n",
    "Training\n",
    "\tMentoring junior consultants on data projects\n",
    "\tTraining newcomers (apprentices, juniors) on Alteryx, Tableau and RPA \n",
    "\tParticipating in the training of PwC France employees on data analysis tools \n",
    "(10 sessions for more than 500 participants)\n",
    "\n",
    "EDUCATION\n",
    "\n",
    "BOOTCAMPS DATA SCIENCE - LE WAGON, FRANCE\t 2022\n",
    "\n",
    "MASTER OF CORPORATE FINANCE ET FINANCIAL MARKET - AIX MARSEILLE UNIVERSITY\t2015-2017\n",
    "\tValedictorian of the Master class (1/149)\n",
    "\tFull Excellence Eiffel Scholarship from the French Government (the best scholarship for students in France)\n",
    "BACHELOR OF ECONOMICS AND MANAGEMENT – PARIS X UNIVERSITY\t2011-2014\n",
    "\tValedictorian of the class (1/134)\n",
    "\tFull scholarship from the Vietnamese Government\n",
    "\n",
    "TECHNICAL SKILLS\n",
    "\n",
    "\tPython, Machine Learning, Deep Learning, Alteryx, SQL, Tableau, Power BI, DAX, UiPath, Process Mining (Celonis), AWS\n",
    "\tCertifications: Data Science, Process Mining Solution Professional, Alteryx Design Core, UiPath Developer\n",
    "\n",
    "SOFT SKILLS\n",
    "\n",
    "\tStrong commercial, numerical acumen, and stakeholder management\n",
    "\tExpertise in analytics methods, modeling, and reporting\n",
    "\tExcellent communication skills\n",
    "\tStrong problem-solving capability and ability to work collaboratively both with technical and non-technical teams\n",
    "\tAdaptable to high-pressure environments and skilled in building relationships\n",
    "\n",
    "REFERENCES\n",
    "\n",
    "Available upon request\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2467070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = f\"\"\"\n",
    "The Senior Data Analyst will be part of the Insights Practice, Data & Analytics team and is responsible for the design and delivery of actionable insights to support decision-making across the Fund. The quality, timeliness and accessibility of these insights allows Cbus to operate as a data-driven fund, capitalising on the value of its data as a strategic asset to ensure member retention, drive exceptional customer experience, generate greater investment returns and enable greater business opportunities while balancing risk and regulatory requirements.\n",
    "\n",
    "\n",
    "In this role you will be responsible for leading the development of complex descriptive analytic processes where a variety of source data points may be consolidated into a simplified model to summarise a behaviour or pattern of what has happened in the past for use by other systems and processes.\n",
    "\n",
    "\n",
    "Responding to ad-hoc requests and deep-dive analysis by designing and delivering high quality data products to meet stakeholders’ requirements in an independently and timely manner. You will evaluate data to determine its suitability for insights and applies caveats to outputs where there are gaps or issues detected but are within an acceptable tolerance for the use case, as determined by the consumer.\n",
    "\n",
    "\n",
    "To be successful you will have demonstrated experience working with stakeholders to understand business problems and translating them into technical requirements and proven experience in extracting and manipulating complex data to drive actionable insights and support decision making.\n",
    "\n",
    "\n",
    "You will have strong data analysis skills in extracting, wrangling, and processing complex data for sophisticated analysis using SQL and Python (Jupyter Notebooks), and advanced Excel. Experience working within an Agile framework and processing diverse and complex structured and unstructured data sets and using modern platform such as AWS, Databricks, Azure and production automation with Git, Airflow and CI/CD tools is highly desirable.\n",
    "\n",
    "\n",
    "Proven experience in designing and building enterprise-grade dashboards using modern visualisation tools (Tableau or Power BI) to visualise analytical output for serving business stakeholders will help you succeed.\n",
    "\n",
    "You will be a team player, love collaborating with your colleagues and enjoy working in a fast paced outcome driven environment. Excellent communication and presentation skills with capability of clearly explaining key insights to a non-technical audience would set you apart.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75ef028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To optimize your resume for the Senior Data Analyst position, you should highlight your experience in designing and delivering actionable insights to support decision-making, as well as your ability to work with stakeholders to understand business problems and translate them into technical requirements. Additionally, emphasize your skills in extracting, wrangling, and processing complex data for sophisticated analysis using SQL and Python, as well as your experience in designing and building enterprise-grade dashboards using modern visualization tools such as Tableau or Power BI. \n",
      "\n",
      "Here's an optimized version of your resume:\n",
      "\n",
      "Skilled data analyst with 6 years of experience analyzing and mining data, developing algorithms, and automating processes to increase business efficiency. Proven expertise in working with large volumes of data and translating complex analytics into actionable insights. Curious and passionate about new technology, eager to implement my skills further to help people work in a different but more efficient and interesting way.\n",
      "\n",
      "RELEVANT PROFESSIONAL EXPERIENCE\n",
      "\n",
      "FREELANCE DATA ANALYST\t07/2022-Present\n",
      "Corum Asset Management - Bank reconciliation\t\n",
      "Corum Asset Management is an independent European asset manager, presented in 7 countries (in the EU and Asia). The Bank Reconciliation project covers the banking transactions for 10 years for all company’s accounts\n",
      "For this job, I provided the cash reconciliation between bank statements and the back office to identify discrepancies and risks:\n",
      "- Designed data pipelines (collected, cleaned, and interpreted) for 10 years of bank transactions (more than €10Bn) received from different sources\n",
      "- Discovered hundreds of discrepancies by cleaning Back Office data (SQL database) and checking Data Quality\n",
      "- Reconciled automatically 90% of bank transfers and 99% of direct debits by working with the business team, challenging their methodology, and developing the calculation rules and matching techniques. The remaining data needed to be checked manually to verify human errors.\n",
      "- Discovered an important gap while analyzing each category of bank statements versus Back Office data (Top-down versus Bottom-up method)\n",
      "- Reported confidential results to the business and technical team, including the output files and user guide for the business team, the progress result for the senior management, and the project's technical documentation.\n",
      "\n",
      "Technical skills: Data Mining, Data Quality, Python, SQL\n",
      "\n",
      "SENIOR DATA ANALYST - PWC FRANCE\t 9/2017 – 4/2021\n",
      "Modeling\t\n",
      "Development of scripts to automate economic models to improve business performance, such as:\n",
      "- Asset Management - Valuation of financial assets: Development of a script to translate complex mathematic formulas developed by actuaries to a user-friendly platform. This helped evaluate financial asset prices (stocks, bonds, real estate assets) in response to economic shocks, inflation, etc. \n",
      "- Banking sector: Creation of normative dictionaries for banking institutions to facilitate the search for regulatory texts. The script reads a regulatory template in input and then scraps all related regulatory texts of each cell in the template.\n",
      "- Payroll model: Development of a salary increase simulation model for 5 000 employees with different scenarios and the business rules of each department. This model helps the senior management to make decisions on salary increases and other strategic decisions on Payroll.\n",
      "\n",
      "Data Analysis: \n",
      "- Conducted in-depth analysis of client's data and identified risks and anomalies.\n",
      "- Performed end-to-end solutions, including cleaning data, developing scripts, creating data visualizations, and conducting restitution workshops.\n",
      "\n",
      "Examples:\n",
      "- SNCF: Analysis of payroll data over 3 years with more than 150 M rows of different fields: remuneration (salary, bonus), paid leaves, etc.\n",
      "SNCF - France's national state-owned railway company, operates the country's national rail traffic. The project was a part of the Annual Audit Job of PwC France in SNCF. Instead of checking a sample of the client’s data, we applied the Data technique to this job to analyze the salary of more than 158 000 SNCF employees.\n",
      "\n",
      "- Decathlon: Reconciliation of quarterly turnover between client payment and data reported in the accounting system (more than 800M€/quarter)\n",
      "Decathlon: is a French sporting goods retailer, presented in 60 countries and regions. The project covers the company turnover for more than 300 shops in France\n",
      "\n",
      "Tools: Alteryx, Tableau, Power BI\n",
      "\n",
      "RPA (Robotic Process Automation)\n",
      "Developing and implementing robots for international clients and PwC France:\n",
      "- Pernod Ricard: \n",
      "Pernod Ricard: is the world’s second-largest wine and spirits seller. The RPA project was a part of the Digitalization Project for the Group Finance Department which aimed to improve business efficiency.\n",
      "o\tMarocain office: Generation of customer invoices from purchase orders (daily run)\n",
      "o\tSwedish office: Creation of new supplier records in the accounting system; Automatization of the customs check on foreign clients (weekly run)\n",
      "All these processes are realized today automatically by robots with a validation step at the end of the process\n",
      "- PwC : \n",
      "o\tData extraction for the Asset Management team (more than 20 000 Excel files downloaded, cleaned and concatenated monthly by robots = 5 full-time juniors + 1 managers  workload)\n",
      "o\tMigration of customer auditing data into the ERP\n",
      "o\tPlanning creation for PwC France employees \n",
      "(65,000 bookings/year = 3 full-time employees workload)\n",
      "\n",
      "Tools: Alteryx, UiPath (RPA)\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "BOOTCAMPS DATA SCIENCE - LE WAGON, FRANCE\t 2022\n",
      "\n",
      "MASTER OF CORPORATE FINANCE ET FINANCIAL MARKET - AIX MARSEILLE UNIVERSITY\t2015-2017\n",
      "- Valedictorian of the Master class (1/149)\n",
      "- Full Excellence Eiffel Scholarship from the French Government (the best scholarship for students in France)\n",
      "\n",
      "BACHELOR OF ECONOMICS AND MANAGEMENT – PARIS X UNIVERSITY\t2011-2014\n",
      "- Valedictorian of the class (1/134)\n",
      "- Full scholarship from the Vietnamese Government\n",
      "\n",
      "TECHNICAL SKILLS\n",
      "\n",
      "- SQL, Python (Jupyter Notebooks), Advanced Excel, AWS, Databricks, Azure, Git, Airflow, CI/CD tools, Tableau, Power BI, Alteryx, DAX, RPA, UiPath, Process Mining (Celonis)\n",
      "\n",
      "SOFT SKILLS\n",
      "\n",
      "- Strong commercial, numerical acumen, and stakeholder management\n",
      "- Expertise in analytics methods, modeling, and reporting\n",
      "- Excellent communication and presentation skills\n",
      "- Strong problem-solving capability and ability to work collaboratively both with technical and non-technical teams\n",
      "- Adaptable to high-pressure environments and skilled in building relationships\n",
      "\n",
      "REFERENCES\n",
      "\n",
      "Available upon request\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "I am applying for a new job, you will provided my resume and a job description. \\\n",
    "I want you to optimize my resume to fit that position.\\\n",
    "\n",
    "The job description is delimited by triple | is :\\\n",
    "|||{job_description}|||\n",
    "\n",
    "My resume is delimited by triple quotes.\\\n",
    "```{resume}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db1b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
